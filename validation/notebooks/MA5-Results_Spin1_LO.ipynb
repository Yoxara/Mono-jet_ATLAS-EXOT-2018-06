{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c69e33",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, glob, copy, re\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import LinearNDInterpolator, interp2d\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LogNorm\n",
    "from IPython.display import display, Markdown\n",
    "from collections import OrderedDict\n",
    "import pylhe\n",
    "import pyslha\n",
    "import xml.etree.ElementTree as ET\n",
    "from particle import Particle, PythiaID\n",
    "#Particle.from_pdgid(211)\n",
    "pythiaid = PythiaID(-4122)\n",
    "p = Particle.from_pdgid(pythiaid.to_pdgid())\n",
    "p.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa81536",
   "metadata": {},
   "source": [
    "### Get hepMC (input) folder and extract model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and pattern for input files\n",
    "inputDir = '/home/yoxara/Eff_MA5_LO'\n",
    "#inputDir = '/media/yoxara/T9/Events_MG5_MA5_ATLAS-EXOT-2018-06_eff/Eff_MA5'\n",
    "listPattern = os.path.join(inputDir, '_run_*/Input/*.list')\n",
    "listFiles = sorted(glob.glob(listPattern))\n",
    "\n",
    "# Define the pattern for output files\n",
    "effPattern = os.path.join(inputDir, '*_run_*/Output/SAF/spin1_run_*/CLs_output.dat')\n",
    "effFiles = sorted(glob.glob(effPattern))\n",
    "\n",
    "# Function to extract the run number from a file path\n",
    "def extract_run_number(file_path):\n",
    "    match = re.search(r'_run_(\\d+)', file_path)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Sort files by their run numbers\n",
    "sorted_listFiles = sorted(listFiles, key=extract_run_number)\n",
    "sorted_effFiles = sorted(effFiles, key=extract_run_number)\n",
    "\n",
    "for input_file, output_file in zip(sorted_listFiles, sorted_effFiles):\n",
    "    input_run = extract_run_number(input_file)\n",
    "    output_run = extract_run_number(output_file)\n",
    "    print(f\"Input Run: {input_run}, Output Run: {output_run}\")\n",
    "    print(f\"Input file: {input_file}\")\n",
    "    print(f\"Output file: {output_file}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(sorted_listFiles)} .list files\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3319ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataDicts = []\n",
    "\n",
    "for inputFile, effFile in zip(sorted_listFiles, sorted_effFiles ):\n",
    "    with open(inputFile, 'r') as f:\n",
    "        hepMCfile = f.read().strip()\n",
    "        hepDir = os.path.dirname(hepMCfile)\n",
    "        print('HepMC input dir=',hepDir)\n",
    "    \n",
    "    try:\n",
    "        banner = sorted(glob.glob(hepDir+'/*banner.txt'), key=os.path.getmtime, reverse=True)\n",
    "        if len(banner) == 0:\n",
    "            print('Banner not found for %s' % inputFile)\n",
    "            continue\n",
    "        elif len(banner) > 1:        \n",
    "            print('\\n%i banner files found for %s. Using %s' \n",
    "                  % (len(banner), inputFile, os.path.basename(banner[0])))\n",
    "        banner = banner[0]\n",
    "        \n",
    "        xtree = ET.parse(banner)\n",
    "        xroot = xtree.getroot()\n",
    "        genInfo = xroot.find('header').find('MGGenerationInfo').text.strip().split('\\n')\n",
    "        genInfo = [x.replace('#', '').strip().split(':') for x in genInfo]\n",
    "        nevts = [eval(x[1]) for x in genInfo if 'Number of Events' in x[0]][0]\n",
    "        xsecPBall = [eval(x[1]) for x in genInfo if 'Integrated weight (pb)' in x[0]]\n",
    "        xsecPBmatched = [eval(x[1]) for x in genInfo if 'Matched Integrated weight (pb)' in x[0]]\n",
    "        if xsecPBmatched:\n",
    "            nevts = nevts * (xsecPBmatched[0] / xsecPBall[0])\n",
    "            xsecPB = xsecPBmatched[0]\n",
    "        else:\n",
    "            xsecPB = xsecPBall[0]\n",
    "\n",
    "        slha = xroot.find('header').find('slha').text\n",
    "        pars = pyslha.readSLHA(slha)\n",
    "        mMed = pars.blocks['MASS'][55]\n",
    "        mDM = pars.blocks['MASS'][52]\n",
    "        gVq = pars.blocks['DMINPUTS'][4] # Mediator-quark vector coupling\n",
    "        gAq = pars.blocks['DMINPUTS'][10] # Mediator-quark axial coupling\n",
    "        gVx = pars.blocks['DMINPUTS'][2] # Mediator-DM vector coupling\n",
    "        gAx = pars.blocks['DMINPUTS'][3] # Mediator-DM axial coupling\n",
    "        print('Cross-section (pb) = %1.3e' % xsecPB)\n",
    "        print('Number of Events = %i' % nevts)\n",
    "        print('mMed = %1.2f GeV, mDM = %1.2f GeV, gVq = %1.2f, gAq = %1.2f, gVx = %1.2f, gAx = %1.2f' \n",
    "              % (mMed, mDM, gVq, gAq, gVx, gAx))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing banner for {inputFile}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    dataDict = {}\n",
    "    if banner:\n",
    "        dataDict['filename'] = hepMCfile\n",
    "        dataDict['Total xsec (pb)'] = xsecPB\n",
    "        dataDict['Total MC Events'] = nevts\n",
    "        if gVx != 0:\n",
    "            dataDict['Coupling'] = 'Vector'\n",
    "        else:\n",
    "            dataDict['Coupling'] = 'Axial'\n",
    "\n",
    "        dataDict['Mode'] = 'DM+QCDjets'\n",
    "\n",
    "        dataDict['$m_{med}$'] = mMed\n",
    "        dataDict['$m_{DM}$'] = mDM\n",
    "        if dataDict['Coupling'] == 'Vector':\n",
    "            dataDict['$g_{DM}$'] = gVx\n",
    "            dataDict['$g_{q}$'] = gVq\n",
    "        else:\n",
    "            dataDict['$g_{DM}$'] = gAx\n",
    "            dataDict['$g_{q}$'] = gAq\n",
    "        \n",
    "    with open(effFile, 'r') as f:\n",
    "        for il, l in enumerate(f.readlines()):\n",
    "            if il == 0:\n",
    "                l = l.replace('#', '')\n",
    "                header = [x.strip() for x in l.split('  ') if x.strip()]\n",
    "                dataDict.update({col : [] for col in header})\n",
    "            else:\n",
    "                pt = [None] * len(dataDict)\n",
    "                if not l.split():\n",
    "                    continue\n",
    "                for ix, x in enumerate(l.split()):\n",
    "                    if not x.strip():\n",
    "                        continue\n",
    "                    try:\n",
    "                        x = eval(x)\n",
    "                    except:\n",
    "                        pass\n",
    "                    if ix > len(dataDict) - 1:\n",
    "                        continue\n",
    "                    pt[ix] = x\n",
    "                for icol, col in enumerate(header):\n",
    "                    dataDict[col].append(pt[icol])\n",
    "    \n",
    "    if '||' in dataDict:\n",
    "        dataDict.pop('||')\n",
    "\n",
    "    allDataDicts.append(dataDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data into a single DataFrame\n",
    "all_df = pd.concat([pd.DataFrame.from_dict(d) for d in allDataDicts], ignore_index=True)\n",
    "all_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc371d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = 'efficiencyMap_Combined.csv'\n",
    "all_df.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'efficiencyMap_Combined.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "bins = data['signal region'].unique()\n",
    "for bin_name in bins:\n",
    "    bin_data = data[data['signal region'] == bin_name]\n",
    "    file_name = f'efficiencyMap__SR_{bin_name}.csv'\n",
    "    bin_data.to_csv(file_name, index=False)\n",
    "    print(f\"Data for {bin_name} saved to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['$m_{med}$', '$m_{DM}$', 'efficiency']\n",
    "for bin_name in bins:\n",
    "    bin_data = data[data['signal region'] == bin_name][columns_to_keep]\n",
    "    #file_name = f'../data/orig/data_eff/axial-vector_new/efficiencyMap__SR_{bin_name}.csv'   \n",
    "    file_name = f'/home/yoxara/smodels-database/13TeV/ATLAS/ATLAS-EXOT-2018-06_eff/orig/axial_vector/efficiencyMap_SR_{bin_name}.csv'\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write('# ' + ','.join(columns_to_keep) + '\\n')\n",
    "        bin_data.to_csv(f, index=False, header=False)\n",
    "    print(f\"Data for {bin_name} saved to {file_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
